import numpy as np


class ConvNet(object):

    def __init__(self, x_initial, y_initial):
        self.x_size = x_initial.shape
        self.y_size y_initial.shape
        self.num_pools = none
        self.num_convolutions none

        for i in range(self.num_pools):
            # create pooling weights
            pass

        for i in range(self.num_convolutions):
            # create convolutional weights
            pass

    def optimize(self, iterations):
        # implement minibatches
        for i in range(iterations):
            # predict and output
            pass
            # backward propagate
            pass

    # Convolution Functions

    def pad(self, array, amount):
        # amount padds that amount in each direction
        # be careful with 3d vectors!!!!
        array = np.pad(array, [(amount, amount), (amount, amount)], mode="constant")
        return array

    # single convolutional operation
    def convolve_window(self, x_window, w, b):
        return np.sum(np.multiply(x_window, w)) + b

    def convolutional_forward(self, x, w, b):
        height = w.shape[0]
        width = w.shape[1]
        length = w.shape[2]
        # apply convolution formula for the number of windows generated by convolution operation
        # loop through convolution windows and apply num_convolutions
        # store convolutions in the next z and then apply activations function to them
        # dont forget to apply normalization and center data around the origin



    def convolutional_backward(self):
        # not really sure how this works yet, but will derive from DL textbook
        pass

    # Pool Funtions

    def pool_forward(self):
        pass

    def pool_backward(self):
        pass

    def creat_mask(self):
        pass

    def distribute_value(self):
        pass
