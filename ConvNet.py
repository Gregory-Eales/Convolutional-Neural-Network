import numpy as np
# loading bar imports
import os
from tqdm import tqdm
import time


class ConvNet(object):

    def __init__(self, x, y):
        # define network topology
        # remember to change # of each type of layers 
        # topology parameter?
        self.x_size = x.shape
        self.y_size = y.shape
        self.num_pools = 1
        self.num_convolutions = 1
        self.num_feed_forward = 1
        # create initital convolutional weights
        self.conv_weights = {}
        self.conv_weights["w1"] = np.random.random([28, 28])
        # create intitial pooling weights
        self.pool_weights = {}
        # create initial feed forward weights
        self.feed_forward_weights = {}

    def sigmoid(self, z):
        return 1/(1+np.exp(-z))

    def sigmoid_prime(self, z):
        return z * np.exp(-1) / np.square(1+np.exp(-z))

    def optimize(self, iterations, self.x):
        # implement minibatches

        print("Training Convolutional Neural Net: ")
        mini_batch = [1, 2, 3, 4, 5, 6, 7, 8, 9]
        for i in range(iterations):
                
                for load_bar in tqdm(mini_batch):
                    # train neural net
                    #self.convolutional_forward(x, w, b, step)
                    # make prediction
                    # update the wieghts based on cost funtion
                    time.sleep(0.7)
            

    # Convolution Functions

    def pad(self, array, amount):
        # amount padds that amount in each direction
        # be careful with 3d vectors!!!!
        array = np.pad(array, [(amount, amount), (amount, amount)], mode="constant")
        return array

    # single convolutional operation
    def convolve_window(self, x_window, w, b):
        return np.sum(np.multiply(x_window, w)) + b

    def convolutional_forward(self, x, w, b, step):
        output_height = w.shape[0]
        otuput_width = w.shape[1]
        output_length = w.shape[2]
        # apply convolution formula for the number of windows generated by convolution operation
        num_x_windows = (x.shape[1] - output_width)/step + 1
        num_y_windows = (x.shape[0] - output_height)/step + 1
        num_z_windows = output_length

        # check to see if paramaters result in a vailid convolution
        #if type(num_x_windows) != int or type(num_y_windows) != int:
            #raise ValueError:
                #print("Error: step size is not valid or insufficient padding")

        # creat output vector
        z = np.zeros([num_x_windows, num_y_windows, num_z_windows])
        # loop through each window and apply convolution to it
        for i in range(num_x_windows):
            # create x window coordinates
            x_start = i*output_width+step*i
            x_end = (i+1)*output_width+step*i
            for j in range(num_y_windows):
                # create y window coordinates
                y_start = j*output_length+step*i
                y_end = (j+1)*output_length+step*j
                for k in range(num_z_windows):
                    # calculate a window element
                    # and add it to the output vector
                    x_window = []
                    x_window = self.convolve_window(x_window, w, b)
                    z[i][j][k] = x_window

        # loop through convolution windows and apply num_convolutions
        # store convolutions in the next z and then apply activations function to them
        # dont forget to apply normalization and center data around the origin



    def convolutional_backward(self):
        # get update equation by taking derivative
        # use weights, bias, and regularization

        for i in range(len(self.w)):
            # update the weights.
            pass

    # Pool Funtions

    def pool_forward(self, a, topology):
        
        output = np.zeros([x, y, z])

        for i in range(x):
            for j in range(y):
                for k in range(z):
                    window = z[l*x:(1 + x) * l][l*y:(1 + x) * l][l*j:(1 + x) * l]
                    pool = np.sum(window)/window.size
                    output[i][j][k] = pool

        return output




    def pool_backward(self):
        pass

    def create_mask(self):
        pass

    def distribute_value(self):
        pass
